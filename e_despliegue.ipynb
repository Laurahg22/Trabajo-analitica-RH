{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Laurahg22/Trabajo-analitica-RH/blob/main/e_despliegue.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Conectar el drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIOzKf7yqNOC",
        "outputId": "77e00aad-63a3-433e-f735-4c475c136876"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd ### para manejo de datos\n",
        "import sqlite3 as sql\n",
        "import joblib\n",
        "import openpyxl ## para exportar a excel\n",
        "import numpy as np\n",
        "import sys #para ver la ruta\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "sys.path ###Ruta directorio qué tiene paquetes\n",
        "sys.path.append('/content/drive/MyDrive/trabajo/Trabajo-analitica-RH') ## este comanda agrega una ruta\n",
        "\n",
        "import a_funciones as funciones  ###archivo de funciones propias"
      ],
      "metadata": {
        "id": "N1A-uxDsrMFM"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### funcion para cargar objeto guardado ###\n",
        "df_2016_d =joblib.load(\"/content/drive/MyDrive/trabajo/Trabajo-analitica-RH/salidas/df_dummies_2016.pkl\")"
      ],
      "metadata": {
        "id": "PgklNC8IoEja"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def columnas_nulos(df):\n",
        "    # Obtener las columnas que tienen al menos un valor nulo\n",
        "    columnas_con_nulos = df.columns[df.isnull().any()].tolist()\n",
        "    return columnas_con_nulos\n",
        "\n",
        "def imp_datos(df, variables):\n",
        "    for variable in variables:\n",
        "        # Calcula la moda de la variable\n",
        "        moda = df[variable].mode()[0]  # Selecciona el primer valor de la moda en caso de que haya múltiples modas\n",
        "        # Imputa los valores nulos con la moda\n",
        "        df[variable].fillna(moda, inplace=True)\n",
        "        # Imprime información sobre los valores nulos imputados\n",
        "        nulos_imputados = df[variable].isnull().sum()\n",
        "    # Devuelve el DataFrame modificado\n",
        "    return df\n",
        "\n",
        "def preparar_datos(df):\n",
        "\n",
        "    list_cat = joblib.load(\"/content/drive/MyDrive/trabajo/Trabajo-analitica-RH/salidas/var_cat.pkl\")\n",
        "    list_dummies = joblib.load(\"/content/drive/MyDrive/trabajo/Trabajo-analitica-RH/salidas/list_dummies.pkl\")\n",
        "    var_names = joblib.load(\"/content/drive/MyDrive/trabajo/Trabajo-analitica-RH/salidas/var_names.pkl\")\n",
        "    scaler = joblib.load(\"/content/drive/MyDrive/trabajo/Trabajo-analitica-RH/salidas/scaler.pkl\")\n",
        "\n",
        "    nulos = columnas_nulos(df)\n",
        "    df_t = imp_datos(df, nulos)\n",
        "    le = LabelEncoder()\n",
        "    for column in list_cat:\n",
        "        if len(df_t[column].unique()) == 2:\n",
        "            df_t[column] = le.fit_transform(df_t[column])\n",
        "    df_t = pd.get_dummies(df_t)\n",
        "    df_t = df_t.loc[:, ~df_t.columns.isin(['EmployeeID'])]\n",
        "\n",
        "    # Asegurar que las dimensiones de los datos coincidan\n",
        "    X2 = scaler.transform(df_t)  # Aplicar la transformación del scaler\n",
        "    X = pd.DataFrame(X2, columns=df_t.columns)\n",
        "    X = X[var_names]  # Seleccionar las variables necesarias\n",
        "\n",
        "    return X\n"
      ],
      "metadata": {
        "id": "wQlXUvsl0Fvx"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Automatizar"
      ],
      "metadata": {
        "id": "wTEmbC-FsaLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__==\"__main__\":\n",
        "    ## Cargar base de datos\n",
        "    df_2016_d\n",
        "    #### Otras transformaciones en python (imputación, dummies y selección de variables)\n",
        "    df_t = preparar_datos(df_2016_d)\n",
        "\n",
        "    ## Cargar modelo y predecir\n",
        "    dt_final = joblib.load(\"/content/drive/MyDrive/trabajo/Trabajo-analitica-RH/salidas/dt_final.pkl\")\n",
        "    predicciones = dt_final.predict(df_t)\n",
        "    pd_pred = pd.DataFrame(predicciones, columns=['Retiros'])\n",
        "\n",
        "    ### Crear base con predicciones ###\n",
        "    perf_pred = pd.concat([df_2016_d['EmployeeID'], df_t, pd_pred], axis=1)\n",
        "\n",
        "    ####LLevar a BD para despliegue\n",
        "    perf_pred[['EmployeeID', 'Retiros']].to_csv(\"/content/drive/MyDrive/trabajo/Trabajo-analitica-RH/salidas/perf_pred.csv\", index=False)\n",
        "\n",
        "    #### Ver_predicciones_bajas ###\n",
        "    emp_pred_bajo = perf_pred.sort_values(by=[\"Retiros\"], ascending=True).head(10)\n",
        "    emp_pred_bajo.set_index('EmployeeID', inplace=True)\n",
        "    pred = emp_pred_bajo.T\n",
        "    coeficientes = pd.DataFrame(np.append([np.nan], [np.nan]), columns=['coeficientes'])  ### agregar coeficientes\n",
        "\n",
        "    pred.to_excel(\"/content/drive/MyDrive/trabajo/Trabajo-analitica-RH/salidas/prediccion.xlsx\")   #### exportar predicciones mas bajas y variables explicativas\n",
        "    coeficientes.to_excel(\"/content/drive/MyDrive/trabajo/Trabajo-analitica-RH/salidas/coeficientes.xlsx\") ### exportar coeficientes para analizar predicciones"
      ],
      "metadata": {
        "id": "P1RC7Wc7ADVJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}